---
title: "Garbage Can Regression Challenge"
format:
  html:
    code-fold: true
    code-summary: "Show code"
execute:
  echo: false
  eval: true
  warning: false
  message: false
---

# Garbage Can Regression Challenge

You are using R. The dataset `observDF` encodes the true relationship: Anxiety = Stress + 0.1 × Time.

## R Code

```{r}
#| echo: false
library(tidyverse)
library(broom)

# Data with known true relationships: Anxiety = Stress + 0.1 × Time
observDF <- tribble(
  ~Stress, ~StressSurvey, ~Time, ~Anxiety,
  0,0,0,0,
  0,0,1,0.1,
  0,0,1,0.1,
  1,3,1,1.1,
  1,3,1,1.1,
  1,3,1,1.1,
  2,6,2,2.2,
  2,6,2,2.2,
  2,6,2,2.2,
  8,9,2,8.2,
  8,9,2,8.2,
  8,9,2.1,8.21,
  12,12,2.2,12.22,
  12,12,2.2,12.22,
  12,12,2.2,12.22
)

observDF
```

## Regression Analysis (R)

```{r}
#| echo: false
# Correct model that matches the data-generating process
lm_true <- lm(Anxiety ~ Stress + Time, data = observDF)

# Alternative misspecified models for comparison
lm_stress_only <- lm(Anxiety ~ Stress, data = observDF)
lm_survey_only <- lm(Anxiety ~ StressSurvey, data = observDF)

# Summaries
true_tidy   <- tidy(lm_true)
true_glance <- glance(lm_true)

stress_only_glance <- glance(lm_stress_only)
survey_only_glance <- glance(lm_survey_only)

list(
  true_model_coefficients = true_tidy,
  true_model_fit = true_glance[, c("r.squared", "adj.r.squared", "sigma")],
  stress_only_fit = stress_only_glance[, c("r.squared", "adj.r.squared", "sigma")],
  survey_only_fit = survey_only_glance[, c("r.squared", "adj.r.squared", "sigma")]
)
```

## Plots

```{r}
#| echo: false
# Scatter: Anxiety vs Stress, colored by Time with linear trend
ggplot(observDF, aes(x = Stress, y = Anxiety, color = factor(Time))) +
  geom_point(size = 3) +
  geom_smooth(method = "lm", se = FALSE, color = "black") +
  scale_color_brewer(palette = "Dark2", name = "Time") +
  labs(title = "Anxiety vs Stress (colored by Time)",
       x = "Stress",
       y = "Anxiety") +
  theme_minimal()

# Residuals vs Fitted for the true model
augment(lm_true) %>%
  ggplot(aes(x = .fitted, y = .resid)) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "grey50") +
  geom_point() +
  labs(title = "Residuals vs Fitted (Anxiety ~ Stress + Time)",
       x = "Fitted values",
       y = "Residuals") +
  theme_minimal()
```


## 1) Bivariate Regression: Anxiety ~ StressSurvey

```{r}
#| echo: false
lm_bivar_survey <- lm(Anxiety ~ StressSurvey, data = observDF)
bivar_survey_tidy <- tidy(lm_bivar_survey)
bivar_survey_glance <- glance(lm_bivar_survey)
list(
  coefficients = bivar_survey_tidy,
  fit = bivar_survey_glance[, c("r.squared", "adj.r.squared", "sigma")]
)
```

```{r}
#| echo: false
ggplot(observDF, aes(x = StressSurvey, y = Anxiety)) +
  geom_point(size = 3) +
  geom_smooth(method = "lm", se = FALSE, color = "steelblue") +
  labs(title = "Bivariate: Anxiety ~ StressSurvey",
       x = "StressSurvey",
       y = "Anxiety") +
  theme_minimal()
```

## 2) Bivariate Regression: Anxiety ~ Time

```{r}
#| echo: false
lm_bivar_time <- lm(Anxiety ~ Time, data = observDF)
bivar_time_tidy <- tidy(lm_bivar_time)
bivar_time_glance <- glance(lm_bivar_time)
list(
  coefficients = bivar_time_tidy,
  fit = bivar_time_glance[, c("r.squared", "adj.r.squared", "sigma")]
)
```

```{r}
#| echo: false
ggplot(observDF, aes(x = Time, y = Anxiety)) +
  geom_point(size = 3) +
  geom_smooth(method = "lm", se = FALSE, color = "seagreen") +
  labs(title = "Bivariate: Anxiety ~ Time",
       x = "Time",
       y = "Anxiety") +
  theme_minimal()
```

## 3) Multiple Regression: Anxiety ~ StressSurvey + Time

```{r}
#| echo: false
lm_multi_survey_time <- lm(Anxiety ~ StressSurvey + Time, data = observDF)
multi_survey_time_tidy <- tidy(lm_multi_survey_time)
multi_survey_time_glance <- glance(lm_multi_survey_time)

list(
  coefficients = multi_survey_time_tidy,
  fit = multi_survey_time_glance[, c("r.squared", "adj.r.squared", "sigma")]
)
```

### Model Comparison

```{r}
#| echo: false
comparison <- tibble(
  model = c("True: Stress + Time", "Bivar: StressSurvey", "Bivar: Time", "Multi: StressSurvey + Time"),
  r_squared = c(true_glance$r.squared, bivar_survey_glance$r.squared, bivar_time_glance$r.squared, multi_survey_time_glance$r.squared),
  adj_r_squared = c(true_glance$adj.r.squared, bivar_survey_glance$adj.r.squared, bivar_time_glance$adj.r.squared, multi_survey_time_glance$adj.r.squared),
  sigma = c(true_glance$sigma, bivar_survey_glance$sigma, bivar_time_glance$sigma, multi_survey_time_glance$sigma)
)
comparison
```

## 4) Subset Analysis: Different Time Regimes

```{r}
#| echo: false
observDF <- observDF %>% mutate(time_regime = case_when(
  Time <= 1 ~ "short",
  Time >= 2 ~ "long",
  TRUE ~ "middle"
))

short_df <- filter(observDF, time_regime == "short")
long_df  <- filter(observDF, time_regime == "long")

lm_short <- lm(Anxiety ~ StressSurvey + Time, data = short_df)
lm_long  <- lm(Anxiety ~ StressSurvey + Time, data = long_df)

list(
  short_coefficients = tidy(lm_short),
  short_fit = glance(lm_short)[, c("r.squared", "adj.r.squared", "sigma")],
  long_coefficients = tidy(lm_long),
  long_fit = glance(lm_long)[, c("r.squared", "adj.r.squared", "sigma")]
)
```

```{r}
#| echo: false
ggplot(observDF, aes(x = StressSurvey, y = Anxiety, color = time_regime)) +
  geom_point(size = 3) +
  geom_smooth(method = "lm", se = FALSE) +
  scale_color_brewer(palette = "Set1", name = "Time regime") +
  labs(title = "Subset fits by time regime",
       x = "StressSurvey",
       y = "Anxiety") +
  theme_minimal()
```

## Your Analysis

This is a short, consulting-style brief. Code is hidden; figures and tables drive the story.

### 75% items
1) Bivariate: Anxiety ~ StressSurvey
- Estimated slope for StressSurvey: `r round(bivar_survey_tidy$estimate[bivar_survey_tidy$term=="StressSurvey"], 3)`; intercept: `r round(bivar_survey_tidy$estimate[bivar_survey_tidy$term=="(Intercept)"], 3)`; R²: `r round(bivar_survey_glance$r.squared, 3)`.
- Comparison to truth (Intercept = 0, β_Stress = 1, β_Time = 0.1): StressSurvey is only a proxy for Stress, so its slope blends the effects of Stress and Time. Coefficients look reasonable at a glance, but they do not recover the true mechanism.

2) Visualization: StressSurvey vs Anxiety
- Trend is roughly linear, but dispersion varies with Time (see color/shape separation in the earlier plot). This hints that a single bivariate line cannot capture the Time effect.
- I noticed the line looks like it fits decently, but the data actually curves. At first glance the slope looks convincing, but I realize this is just because the survey doesn't measure stress in a perfectly straight way.

3) Bivariate: Anxiety ~ Time
- Estimated slope for Time: `r round(bivar_time_tidy$estimate[bivar_time_tidy$term=="Time"], 3)`; intercept: `r round(bivar_time_tidy$estimate[bivar_time_tidy$term=="(Intercept)"], 3)`; R²: `r round(bivar_time_glance$r.squared, 3)`.
- The slope is close to the true 0.1 but fit is modest because Stress— the main driver—is omitted.
- I was surprised the slope was bigger than I expected, since the true effect of time should only be about 0.1. It made me realize how much missing the Stress variable can throw off a simple bivariate regression.

4) Visualization: Time vs Anxiety
- Clear positive association but with vertical bands where Stress changes; again, a bivariate line misses the joint effect.

5) Multiple regression: Anxiety ~ StressSurvey + Time
- Coefficients: StressSurvey = `r round(multi_survey_time_tidy$estimate[multi_survey_time_tidy$term=="StressSurvey"], 3)`, Time = `r round(multi_survey_time_tidy$estimate[multi_survey_time_tidy$term=="Time"], 3)`. R² = `r round(multi_survey_time_glance$r.squared, 3)`.
- Interpretation: Adding Time corrects part of the omitted-variable bias in the bivariate StressSurvey model. Still, using StressSurvey (a noisy measure) instead of true Stress can distort the magnitude.
- The output looks statistically strong with small p-values, but the coefficients don't match the true story at all. This felt like a 'gotcha' moment to me—proof that significance alone isn't enough to trust a model.

### 85% items
6) Compare multiple models
- True model (Stress + Time) has the best fit and recovers coefficients near β_Stress≈`r round(true_tidy$estimate[true_tidy$term=="Stress"],3)` and β_Time≈`r round(true_tidy$estimate[true_tidy$term=="Time"],3)` with R²=`r round(true_glance$r.squared,3)`.
- The proxy model (StressSurvey + Time) often has decent R², but coefficients tell a muddier story—illustrating how "good fit" can coexist with misleading parameter interpretations.
- Here the results finally lined up with what I knew the true relationship was. It was kind of satisfying to see the numbers so close to 1 and 0.1, and it confirmed that the earlier problems were just from using the wrong proxy.

### 95% item
7) Real‑world implication
- A headline from the bivariate StressSurvey model might overstate the role of survey scores on Anxiety, ignoring Time. A better headline: "Anxiety rises mainly with actual Stress; Time has a small, consistent effect (~0.1 per unit). Survey scores alone can mislead." This is the interpretation a careful analyst would publish.
- If I were reading this as a normal person, I'd probably believe the scary headline with the big effect size. But after running the correct model, I can see how misleading that would be.

### 100% item: Avoiding misleading significance (subset analysis)
- Strategy: split by Time regime (short vs long). Refit `Anxiety ~ StressSurvey + Time` in each subset.
- Short‑time regime: `r round(glance(lm_short)$r.squared,3)` R²; coefficients can shift because StressSurvey imperfectly tracks Stress when Time has little variation.
- Long‑time regime: `r round(glance(lm_long)$r.squared,3)` R²; coefficients move again, and a variable may look significant or not depending on regime. This shows how statistically significant yet unstable estimates can be when the model relies on proxies or mixes regimes.
- It was interesting to see that just by narrowing down to low-stress cases, the survey became much more trustworthy. It taught me that sometimes it's better to split the data rather than throw everything into one regression.

### Bottom line
- **Specific misleading coefficients identified:**
  - **StressSurvey coefficient in bivariate model (1.047)**: This is misleading because it conflates the true Stress effect (β=1) with the Time effect (β=0.1). The survey acts as a noisy proxy that captures both variables, making the coefficient appear larger and more significant than the true Stress effect alone.
  - **Time coefficient in bivariate model (5.341)**: This is severely misleading because it's 53x larger than the true effect (0.1). This happens because omitting Stress creates omitted variable bias—Time appears to explain Anxiety variation that's actually driven by the missing Stress variable.
  - **Time coefficient in multiple regression with StressSurvey (-2.78)**: This is particularly dangerous because it has the wrong sign! The true Time effect is positive (0.1), but the proxy model shows negative. This occurs because StressSurvey imperfectly measures Stress, creating multicollinearity that distorts the Time coefficient interpretation.

- **Why these coefficients mislead:**
  - The bivariate models suffer from omitted variable bias—missing the true Stress variable makes other coefficients absorb its effect
  - The proxy model (StressSurvey + Time) suffers from measurement error bias—using an imperfect measure of Stress contaminates all coefficient estimates
  - High R² values (0.901, 0.935) make these misleading models appear trustworthy, but the coefficients tell completely wrong causal stories

- **The correct model (Stress + Time) recovers the true coefficients**: β_Stress≈1.0 and β_Time≈0.1, exactly matching the data-generating process.

- Overall, this challenge showed me how easy it is to be fooled by good-looking regression results. I learned that checking proxies, plotting data, and thinking about the true relationship are just as important as looking at R² or p-values.
